Script started on 2025-04-06 12:30:30+00:00 [TERM="xterm" TTY="/dev/pts/12" COLUMNS="104" LINES="53"]
 PyTorch version: 2.6.0+cu126
 CUDA version 	: 12.6
 GPU cuda:(0) 	: NVIDIA GeForce RTX 4090 
 --------------------------------------------------
 [Benchmark] Attention unified benchmark for Dilated_Mask
 bs:1 | h_num:12 | seq:128  |  FlashAttn2  : 0.132 ms / iter
 bs:1 | h_num:12 | seq:128  |  Torch Naive : 0.250 ms / iter
 bs:1 | h_num:12 | seq:128  |   FlexAttn   : 0.123 ms / iter
 bs:1 | h_num:12 | seq:128  |  ByteTrans   : 0.088 ms / iter
 bs:1 | h_num:12 | seq:128  |  Our Kernel  : 0.053 ms / iter

 bs:1 | h_num:12 | seq:256  |  FlashAttn2  : 0.131 ms / iter
 bs:1 | h_num:12 | seq:256  |  Torch Naive : 0.248 ms / iter
 bs:1 | h_num:12 | seq:256  |   FlexAttn   : 0.121 ms / iter
 bs:1 | h_num:12 | seq:256  |  ByteTrans   : 0.090 ms / iter
 bs:1 | h_num:12 | seq:256  |  Our Kernel  : 0.053 ms / iter

 bs:1 | h_num:12 | seq:512  |  FlashAttn2  : 0.142 ms / iter
 bs:1 | h_num:12 | seq:512  |  Torch Naive : 0.251 ms / iter
 bs:1 | h_num:12 | seq:512  |   FlexAttn   : 0.120 ms / iter
 bs:1 | h_num:12 | seq:512  |  ByteTrans   : 0.107 ms / iter
 bs:1 | h_num:12 | seq:512  |  Our Kernel  : 0.051 ms / iter

 bs:1 | h_num:12 | seq:1024  |  FlashAttn2  : 0.143 ms / iter
 bs:1 | h_num:12 | seq:1024  |  Torch Naive : 0.246 ms / iter
 bs:1 | h_num:12 | seq:1024  |   FlexAttn   : 0.122 ms / iter
 bs:1 | h_num:12 | seq:1024  |  ByteTrans   : 0.192 ms / iter
 bs:1 | h_num:12 | seq:1024  |  Our Kernel  : 0.053 ms / iter

 bs:1 | h_num:12 | seq:2048  |  FlashAttn2  : 0.136 ms / iter
 bs:1 | h_num:12 | seq:2048  |  Torch Naive : 1.202 ms / iter
 bs:1 | h_num:12 | seq:2048  |   FlexAttn   : 0.128 ms / iter
 bs:1 | h_num:12 | seq:2048  |  Our Kernel  : 0.101 ms / iter

 bs:1 | h_num:12 | seq:4096  |  FlashAttn2  : 0.356 ms / iter
 bs:1 | h_num:12 | seq:4096  |  Torch Naive : 3.927 ms / iter
 bs:1 | h_num:12 | seq:4096  |   FlexAttn   : 0.276 ms / iter
 bs:1 | h_num:12 | seq:4096  |  Our Kernel  : 0.146 ms / iter

 bs:8 | h_num:12 | seq:128  |  FlashAttn2  : 0.130 ms / iter
 bs:8 | h_num:12 | seq:128  |  Torch Naive : 0.250 ms / iter
 bs:8 | h_num:12 | seq:128  |   FlexAttn   : 0.121 ms / iter
 bs:8 | h_num:12 | seq:128  |  ByteTrans   : 0.088 ms / iter
 bs:8 | h_num:12 | seq:128  |  Our Kernel  : 0.053 ms / iter

 bs:8 | h_num:12 | seq:256  |  FlashAttn2  : 0.130 ms / iter
 bs:8 | h_num:12 | seq:256  |  Torch Naive : 0.245 ms / iter
 bs:8 | h_num:12 | seq:256  |   FlexAttn   : 0.119 ms / iter
 bs:8 | h_num:12 | seq:256  |  ByteTrans   : 0.089 ms / iter
 bs:8 | h_num:12 | seq:256  |  Our Kernel  : 0.052 ms / iter

 bs:8 | h_num:12 | seq:512  |  FlashAttn2  : 0.132 ms / iter
 bs:8 | h_num:12 | seq:512  |  Torch Naive : 0.333 ms / iter
 bs:8 | h_num:12 | seq:512  |   FlexAttn   : 0.118 ms / iter
 bs:8 | h_num:12 | seq:512  |  ByteTrans   : 0.359 ms / iter
 bs:8 | h_num:12 | seq:512  |  Our Kernel  : 0.071 ms / iter

 bs:8 | h_num:12 | seq:1024  |  FlashAttn2  : 0.191 ms / iter
 bs:8 | h_num:12 | seq:1024  |  Torch Naive : 1.901 ms / iter
 bs:8 | h_num:12 | seq:1024  |   FlexAttn   : 0.169 ms / iter
 bs:8 | h_num:12 | seq:1024  |  ByteTrans   : 1.140 ms / iter
 bs:8 | h_num:12 | seq:1024  |  Our Kernel  : 0.240 ms / iter

 bs:8 | h_num:12 | seq:2048  |  FlashAttn2  : 0.717 ms / iter
 bs:8 | h_num:12 | seq:2048  |  Torch Naive : 9.430 ms / iter
 bs:8 | h_num:12 | seq:2048  |   FlexAttn   : 0.492 ms / iter
 bs:8 | h_num:12 | seq:2048  |  Our Kernel  : 0.412 ms / iter

 bs:8 | h_num:12 | seq:4096  |  FlashAttn2  : 2.774 ms / iter
 bs:8 | h_num:12 | seq:4096  |  Torch Naive : 32.396 ms / iter
 bs:8 | h_num:12 | seq:4096  |   FlexAttn   : 1.621 ms / iter
 bs:8 | h_num:12 | seq:4096  |  Our Kernel  : 0.866 ms / iter

 bs:16 | h_num:12 | seq:128  |  FlashAttn2  : 0.129 ms / iter
 bs:16 | h_num:12 | seq:128  |  Torch Naive : 0.246 ms / iter
 bs:16 | h_num:12 | seq:128  |   FlexAttn   : 0.118 ms / iter
 bs:16 | h_num:12 | seq:128  |  ByteTrans   : 0.090 ms / iter
 bs:16 | h_num:12 | seq:128  |  Our Kernel  : 0.051 ms / iter

 bs:16 | h_num:12 | seq:256  |  FlashAttn2  : 0.128 ms / iter
 bs:16 | h_num:12 | seq:256  |  Torch Naive : 0.246 ms / iter
 bs:16 | h_num:12 | seq:256  |   FlexAttn   : 0.121 ms / iter
 bs:16 | h_num:12 | seq:256  |  ByteTrans   : 0.090 ms / iter
 bs:16 | h_num:12 | seq:256  |  Our Kernel  : 0.052 ms / iter

 bs:16 | h_num:12 | seq:512  |  FlashAttn2  : 0.130 ms / iter
 bs:16 | h_num:12 | seq:512  |  Torch Naive : 0.974 ms / iter
 bs:16 | h_num:12 | seq:512  |   FlexAttn   : 0.121 ms / iter
 bs:16 | h_num:12 | seq:512  |  ByteTrans   : 0.661 ms / iter
 bs:16 | h_num:12 | seq:512  |  Our Kernel  : 0.132 ms / iter

 bs:16 | h_num:12 | seq:1024  |  FlashAttn2  : 0.385 ms / iter
 bs:16 | h_num:12 | seq:1024  |  Torch Naive : 3.783 ms / iter
 bs:16 | h_num:12 | seq:1024  |   FlexAttn   : 0.298 ms / iter
 bs:16 | h_num:12 | seq:1024  |  ByteTrans   : 2.223 ms / iter
 bs:16 | h_num:12 | seq:1024  |  Our Kernel  : 0.445 ms / iter

 bs:16 | h_num:12 | seq:2048  |  FlashAttn2  : 1.442 ms / iter
 bs:16 | h_num:12 | seq:2048  |  Torch Naive : 18.824 ms / iter
 bs:16 | h_num:12 | seq:2048  |   FlexAttn   : 0.919 ms / iter
 bs:16 | h_num:12 | seq:2048  |  Our Kernel  : 0.689 ms / iter

 bs:16 | h_num:12 | seq:4096  |  FlashAttn2  : 5.541 ms / iter
 bs:16 | h_num:12 | seq:4096  |  Torch Naive : 63.972 ms / iter
 bs:16 | h_num:12 | seq:4096  |   FlexAttn   : 3.124 ms / iter
 bs:16 | h_num:12 | seq:4096  |  Our Kernel  : 1.297 ms / iter


Script done on 2025-04-06 12:32:41+00:00 [COMMAND_EXIT_CODE="0"]
